[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/DH_140_Final.html",
    "href": "posts/DH_140_Final.html",
    "title": "Reading Time: The Invention of Time Throughout the Industrial Revolution",
    "section": "",
    "text": "Question\nHow has the usage of the word time evolved throughout literary works ranging from before the Industrial revolution until 1899?\n\n\nIntroduction\nUntil recently, the literary scholar has employed the tool of close reading to assist in analyzing text: reading between the lines to find the micro interactions between a novel, the author, the novel and its culture, the novel and its political atmosphere, the novel and science, etc. In close reading, the scholar picks a single work to shreds, interpreting the text, in ways that even the author could not imagine. For example, using textual devices such as the interruption within a novel such as Laurence Sterne’s The Life and Opinions of Tristram Shandy, Gentleman a critic could explicate the notion of how time was perceived in the mid 1700’s. Or, uncovering trauma within an author’s text could unveil suppressed personal memories that only manifest when the person is presented with certain objects or instances. Thus scholars have typically only used their own knowledge, coupled with other philosophical and scholarly work to one novel at a time.\nEnter then, the computer era, and the invention of programming tools such as Python, R, and automated tools such as Voyant that are able to, with shocking rapidity, scan an entire corpus of texts. With tools such as these, a new method of analysis became available to scholars: distant reading. Right at the beginning of the new century, literary critic Franco Moretti (2000) coined the term, defining distant reading as “understanding literature not by studying particular texts, but by aggregating and analyzing massive amounts of data”. By aggregating massive amounts of text, the scholar can see trends and patterns throughout whole periods of time by running programs such as those mentioned above, a method that close reading could simply not do. In distant reading, the macro interactions of novels are revealed. In distant reading, the macro interactions of novels are revealed, meaning the interactions between novels and their time periods, between a corpus of authors, etc. This new approach can reveal insights that would be impossible – or extremely difficult – to uncover through traditional methods. For example, patterns in language or themes used by a corpus of authors can be identified, and the gradual increase of the usages of certain words can be used to examine broader cultural trends, including but not limited to the relationship between literature and scientific ideas. These analyses are not without their limitations however. As distant reading relies on computational analysis rather than the human eye, results can sometimes be difficult to conceptualize. However, despite this, it has emerged as an invaluable tool for literary scholars to understand works within their broader context. For this project, I will be doing just that. I will be telling the story of how industrialization affected human thought gradually over the course of ~400 years through literary works. By choosing works from the pristine, pre-industrialized periods, I hope to show the subtle changes of thought based on word usage in literature.\n\n\nCleaning & Statistical Analysis\n\nimport pandas as pd\n\n# making dataframe\ndf = pd.read_csv(\"data set literature.csv\")\n\nImports my literature dataset which includes 33 works ranging from 1500-1902.\n\nimport requests\n\n# Read the data from the CSV file\ndf = pd.read_csv('data set literature.csv')\n\n# Drop rows with missing URLs\ndf.dropna(subset=['Gutenberg Link'], inplace=True)\n\n# Loop through each URL in the DataFrame and download the content\nfor i, row in df.iterrows():\n    url = row['Gutenberg Link']\n    response = requests.get(url)\n    with open(f'book{i}.txt', 'wb') as f:\n        f.write(response.content)\n\n\nThis code reads in data from a CSV file (‘data set literature.csv’), drops any rows where the ‘Gutenberg Link’ column has a missing value, and then loops through each remaining row in the DataFrame to download the content of the corresponding URL using the requests library. The content is saved to a file with the name ‘book{i}.txt’, where i is the index of the current row in the DataFrame.\n\nimport os\nimport re\nimport requests\n\n# define the URL to download\nurl = 'https://www.gutenberg.org/cache/epub/41256/pg41256-images.html'\n\n# define the directory path to save the file\ndirectory = '1700-1800_texts'\n\n# create the directory if it doesn't exist\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\n# define the filename to save the file as\nfilename = os.path.join(directory, 'pg41256-images.html')\n\n# download the webpage\nresponse = requests.get(url)\n\n# save the HTML file\nwith open(filename, 'wb') as f:\n    f.write(response.content)\n\nThis code downloads an HTML webpage from the specified URL (‘https://www.gutenberg.org/cache/epub/41256/pg41256-images.html’) using the requests library, and saves it to a file with the name ‘pg41256-images.html’ in the specified directory (‘1700-1800_texts’). If the directory does not exist, the code creates it using the os library. I did this because I realized while initially sorting my data that my 1700-1800 set did not have the amount of texts I needed.\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\n# Add custom stopwords\ncustom_stop_words = [\"new\", \"york\", \"city\", \"like\", \"would\"]\nstop_words = stop_words.union(custom_stop_words)\n\nThe code imports a list of common English words called “stopwords” from NLTK, and creates a set of these words. It also adds some additional custom stopwords to the set. This set will be used to remove these words from text data in later processing.\n\n# Define a helper function to count occurrences of a word in a file\ndef count_word_in_file(filename, word):\n    with open(filename, 'r', encoding='iso-8859-1') as f:\n        contents = f.read()\n        words = contents.lower().split()\n        word_count = words.count(word)\n        return word_count\n\n# Read in the dataframe\ndf = pd.read_csv(\"data set literature.csv\")\n\n# Loop through each book file and count the number of times the word \"time\" appears\ntime_counts = []\nfor i, row in df.iterrows():\n    filename = f'book{i}.txt'\n    word_count = count_word_in_file(filename, 'time')\n    time_counts.append(word_count)\n\n# Add the time count values as a new column in the dataframe\ndf['Time Count'] = time_counts\n\nThe code defines a function to count the occurrences of a word in a file and uses it to count the number of times the word “time” appears in each book file. The word counts are stored in a list and added as a new column called ‘Time Count’ to the DataFrame.\n\ndef extract_words_from_file(filename):\n    with open(filename, 'r', encoding='iso-8859-1') as f:\n        contents = f.read()\n        words = ''.join(c if c.isalpha() else ' ' for c in contents).lower().split()\n        return words\n\n        return words\nfor i in range(len(df)):\n    filename = f\"book{i}.txt\"\n    words = extract_words_from_file(filename)\n\nThe code defines a function called extract_words_from_file which takes a filename as input, opens the file, and extracts all the words in it using a regular expression. The extracted words are returned as a list.\nThen, it loops through each row in the DataFrame and extracts the words from the corresponding book file using the extract_words_from_file function. The extracted words are stored in a list called words.\n\n# Loop through each row in the DataFrame and print the title, author, and date\nfor i, row in df.iterrows():\n    title = row['Title']\n    author = row['Author']\n    date = row['Date']\ndef count_word_in_file(filename, word):\n    with open(filename, 'r', encoding='iso-8859-1') as f:\n        contents = f.read()\n        words = contents.lower().split()\n        word_count = words.count(word)\n        return word_count\n\n\nThis code loops through each row in a Pandas DataFrame (which contains my texts) and extracts the title, author, and date for each row. It also defines a helper function that counts the number of occurrences of a word in a file.\n\ndef count_word_in_file(filename, word):\n    with open(filename, 'r', encoding='iso-8859-1') as f:\n        contents = f.read()\n        words = contents.lower().split()\n        word_count = words.count(word)\n        return word_count\n\n# Loop through each book file and count the number of times the word \"time\" appears\nfor i, row in df.iterrows():\n    filename = f'book{i}.txt'\n    word_count = count_word_in_file(filename, 'time')\n\nThis code defines a function count_word_in_file that counts the number of times a word appears in a file. Then it loops through each book file and counts the number of times the word ‘time’ appears in the file using the count_word_in_file function.\n\n\nA Broad Stroke\nThe expansion of London during the latter half of the 18th century saw the rise of industry, with the first modern factory, the Slater Mill. While this benefited humanity in ways that were not immediately apparent, the damage this would do would be felt to the present day such as deforestation, increased carbon dioxide emissions, and constant light pollution. The industrialization of cities like London also polluted human life, with young children being forced into dangerous factory work and losing cherished innocence through harsh working conditions. The damages and pain inflicted on children and the working classes were not the only effects of industrialization, it also forever changed humanity’s natural perception of time. This period of history marked the beginning of a significant shift in human thought and behavior, as people began to think of time as something that could be measured, standardized, and used for economic purposes.\n\nimport matplotlib.pyplot as plt\n\n# read in the dataset\ndf = pd.read_csv(\"data set literature.csv\")\n\n# create a new column for the word count of \"time\" in each book\ndf['Time Count'] = 0\n\n# loop through each book file and count the number of times the word \"time\" appears\nfor i, row in df.iterrows():\n    filename = f'book{i}.txt'\n    with open(filename, 'r', encoding='iso-8859-1') as f:\n        contents = f.read()\n        words = contents.lower().split()\n        word_count = words.count('time')\n        df.at[i, 'Time Count'] = word_count\n\n# filter the dataframe to only include books published between 1532 and 1902\nfiltered_df = df[(df['Date'] >= 1550) & (df['Date'] <= 1902)]\n\n# group the filtered dataframe by year and sum the time counts\ngrouped_df = filtered_df.groupby('Date')['Time Count'].sum().reset_index()\n\n# plot a histogram of the time count over the years\nplt.hist(grouped_df['Date'], bins=20, weights=grouped_df['Time Count'], color='blue', alpha=0.5)\nplt.title('Usage of the word \"time\" in novels published from 1532 to 1902')\nplt.xlabel('Date')\nplt.ylabel('Frequency of \"time\"')\nplt.show()\n\n\n\n\nThe code above reads in a dataset of literature and creates a new column to count the number of times the word “time” appears in each book file. It then filters the dataframe to only include books published between 1532 and 1902, groups the filtered dataframe by year, and sums the time counts. Finally, it creates a histogram of the time count over the years using matplotlib. The histogram shows the frequency of the word “time” in novels published from 1532 to 1902.\n\n\nOutlier\nThe graph above shows the usage of the word “time” in the novels I collected from 1532 - 1902. Though the graph supports my analysis by showing most of the usage between 1800-1902, there is one major outlier, Don Quixote, by Miguel Cervantes, which was published in 1605. It is common thought Cervantes was “far ahead of [his] time” with his seminal novel. Scholars even state that he played with themes that did not become popular for another century or two, which ties in perfectly with my observation that “time” was not showing more frequently in novels before 1700.\n\n\n1790 to 1902\nThe period from 1800 to 1902 saw significant changes in the world, with the emergence of industrialization and the rise of the working class. The first set of literary works that were chosen were from this period of time. Within a corpus of ten works of Gothic literature from across the century, ranging from Mary Shelly’s Frankenstein to Bram Stoker’s Dracula, the word time was used a total of 2,320 times. This is unsurprising, as factory work and living by the clock was basically a standard for the working class in the Victorian era. Not to mention the construction of Big Ben in 1843, would have cemented the concept of time in everyone’s minds. Not only Big Ben, but the railway as well made the passage of time a constant in Victorian thought. So much so, that scholars read Dracula as a manifestation of this. Some claim that Stoker critiques the automaton-like nature of living by the clock. Johnathan Harker’s trip across the forest to the Count’s place of residence is viewed as time travel to a place locked in the past, and while this past is full of fears rooted in superstition, it is still quaint. Big Ben, the railroads, and Dracula all lead back to industrialization and factory work, showing how living by the clock dominated cultural thought. This is seen in the fact that even though Dracula is told through a retelling of journal entries, as David Seed (1985, 74) states “nothing stands in the way of the narrative’s linear impetus”, like the clock that continously ticks forward. The fact that the novels chosen for this dataset through this time period have the highest word count of “time” perfectly demonstrates this.\nI chose this wide ranging span of years because in 1902, Hound of the Baskervilles by Sir Arthur Conan Doyle was published, which still heavily relied on Victorian values. Ann Radcliff’s A Sicilian Romance also predicts Victorian values and holds Gothic values held in Victorian decades.\n\nimport os\nimport re\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\n\n# Create a custom stopwords list\ncustom_stopwords = set(stopwords.words('english'))\ncustom_stopwords.update(['href', 'div', 'span', 'class', 'dquo'])\ncustom_stopwords.update(['br', 'ldquo', 'p', 'mdash', 'footnote', 'rsquo',\n                         'rdquo', 'pagenum', 'u','width','nbsp', 'id', 'FNanchor', 'name', 'page', \n                         'pagei', 'hb', 'stanza', 'said', 'one', 'say', 'would', 'right', 'lnumber', 'Quixote', 'Sancho',\n                        'linenum', 'F', 'label', 'label', 'pfn', 'F', 'h', 'td td', 'Luther', 'may', 'see', 'make', 'man', 'come',\n                        'b', 'trtd', 'thy', 'thee', 'like', 'td td', 'tr', 'td', 'pg', 'could', 'upon', 'much', 'made', 'shall', 'two', 'still', 'Quasimodo', 'gringoire', 'head words', 'eye'])\n\n# Read the text files from the directory\ntext = ''\nfor filename in os.listdir('1790-1902_texts'):\n    # Add an if statement to skip hidden directories\n    if not filename.startswith('.'):\n        with open(f'1790-1902_texts/{filename}', 'r', encoding='ISO-8859-1') as f:\n            text += f.read()\n# Remove non-alphabetic characters\ntext = re.sub('[^A-Za-z]+', ' ', text)\n\n# Generate the wordcloud\nwc = WordCloud(width=500, height=600, background_color='black', stopwords=custom_stopwords).generate(text)\n\n# Generate the bar chart\nwords = re.findall('\\w+', text)\nword_count = {}\nfor word in words:\n    if word.lower() in custom_stopwords:\n        continue\n    if word.lower() == 'eye':\n        continue\n    if word not in word_count:\n        word_count[word] = 1\n    else:\n        word_count[word] += 1\nsorted_word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:5]\nx, y = zip(*sorted_word_count)\n\n# Display the wordcloud and bar chart side by side\nfig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n# Wordcloud\naxs[0].imshow(wc, interpolation='bilinear')\naxs[0].axis('off')\naxs[0].set_title('Wordcloud')\n\n# Bar chart\naxs[1].bar(x, y)\naxs[1].set_title('Top 5 Most Used Words')\naxs[1].set_xlabel('Words')\naxs[1].set_ylabel('Frequency')\n\nplt.show()\n\n\n\n\nThe visualizations above reveal a significant emphasis on temporal words like “time”, “moment”, and “day”, as well as body words such as “eyes”, “head”, and “hand” within the 1790-1902 texts. Given that industrialization was in full swing during this time period and factory work was becoming the norm, it is reasonable to expect that these types of words would be prevalent in the language of the era. It is interesting to note that the word hand is large in the word cloud, but nowhere to be seen on the baar chart.\n\n\nNote\nThe wordcloud and bar chart represent different types of visualizations, and as such, they emphasize different aspects of the data. The wordcloud displays words in a visual hierarchy based on their frequency, while the bar chart displays the raw frequency of the top 5 most commonly used words. Hence why in the wordcloud “time” is shown larger than “eyes” and the bar chart shows “eyes” as having just slightly more usage.\n\n\n1700-1800\nFrom Daniel Defoe’s Robinson Crusoe to Laurence Sterne’s The Life and Opinions of Tristram Shandy, Gentleman, and into the beginnings of Gothic literature, the notion of precise time began seeping into thought between the years 1700 and 1800. The 1,743 instances of the word time, in this subset of works, is a clear statement of the growing phenomenon of relying on the clock. The actual beginnings of the Industrial Revolution are hotly debated, with some placing the start of it around 1750, and others saying around 1760. A novel such as Tristram Shandy would support the former with its famous final lines of the opening page “‘pray, my dear,’ quoth my mother’ have you not forgot to wind up the clock?” (Sterne, 1750, 6). On this page, the narrator Tristram, blames this interruption by his mother during his parents’ intimacy for him being generally unlucky. This can be attributed to the rise of the Industrial Revolution, which led to significant change in how people perceived time and the value of their time. As scholar Amit Yahevstates “during this period clocks came to control industrial production” (2018, 873). Tristram’s father was a man so reliant on the clock, that every little bit of his life was dependent on its ticks. It would make sense then for the question to be such a pivotal one, as it interrupted the most important aspect of production to an industrial society: the procreation of new life. Since, as is well known, the Industrial Revolution was notorious for employing massive amounts of children under extremely poor working conditions.\n\nfrom collections import Counter\n\n\n# Create a custom stopwords list\ncustom_stopwords = set(stopwords.words('english'))\ncustom_stopwords.update(['href', 'div', 'span', 'class', 'dquo'])\ncustom_stopwords.update(['br', 'ldquo', 'p', 'mdash', 'footnote', 'rsquo',\n                         'rdquo', 'pagenum', 'u','width','nbsp', 'id', 'FNanchor', 'name', 'page', \n                         'pagei', 'hb', 'stanza', 'said', 'one', 'say', 'would', 'right', 'lnumber', 'Quixote', 'Sancho',\n                        'linenum', 'F', 'label', 'label', 'pfn', 'F', 'h', 'td td', 'Luther', 'may', 'see', 'make', 'man', 'come',\n                        'b', 'trtd', 'thy', 'thee', 'like', 'td td', 'tr', 'td', 'pg', 'could', 'upon', 'much', 'made', 'shall', 'well',\n                        'must', 'every', 'small', 'good', 'great', 'little', 'I', 'he', 'the', 'but', 'she'])\n\n# Read the text files from the directory\ntext = ''\nfor filename in os.listdir('1700-1800_texts'):\n    # Add an if statement to skip hidden directories\n    if not filename.startswith('.'):\n        with open(f'1700-1800_texts/{filename}', 'r', encoding='ISO-8859-1') as f:\n            text += f.read()\n# Remove non-alphabetic characters\ntext = re.sub('[^A-Za-z]+', ' ', text)\n\n# Tokenize the text and remove stopwords\ntokens = [word.lower() for word in re.findall('\\w+', text) if word.lower() not in custom_stopwords]\n\n# Count the frequency of each word\nword_counts = Counter(tokens)\n\n# Get the top 5 words and their frequencies\ntop_words = word_counts.most_common(5)\n\n# Create a bar chart of the top 5 words\nwords = [word[0] for word in top_words]\ncounts = [word[1] for word in top_words]\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nfig.suptitle('Word Frequency Analysis')\n\naxs[0].imshow(WordCloud(width=500, height=600, background_color='black', stopwords=custom_stopwords).generate(text), interpolation='bilinear')\naxs[0].axis('off')\n\naxs[1].bar(words, counts)\naxs[1].set_title('Top 5 Words')\naxs[1].set_xlabel('Words')\naxs[1].set_ylabel('Frequency')\n\nplt.show()\n\n\n\n\nAccording to the word cloud, the term “time” appears to be increasingly significant. The bar chart indicates that “time” has been used over 1600 times in the given texts, indicating a gradual rise in its usage. While it is less frequent than the usage from 1790-1902, it is still growing in prevalence.\n\n\n1500-1700\nBetween the years 1500 and 1700, the world underwent a significant transformation. This period saw the Age of Discovery, the Renaissance, the Reformation, and the Scientific Revolution. It was a time of great social, economic, and cultural changes that laid the foundation for the clock’s growing importance in the following centuries. A broader scan of the words revealed more religious words such as “heaven” and “God” being more common. Despite the transformation that occurred during this period, it is fascinating to note the non-use of the word “time”. A possibility for this is that perhaps the concept of time was still evolving in peoples’ minds, people who were farmers, agriculture workers who were not as beholden to clocks, but rather to the rise and fall of the sun and the change of seasons. Though clocks were popping up here and there, bell towers were still enough for most people. The clock as it is known today (mostly) was not adopted in households until the late 15th century, with the first watch appearing in Italy, France, and Germany in 1492, and then only in aristocratic households. From then on, the importance of time and the measurement of it became more and more prominent in people’s lives. The Industrial Revolution of the 18th and 19th centuries would further increase the importance of timekeeping, as factories needed to be run on strict schedules to maximize productivity.\n\nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\n\n\n# Create a custom stopwords list\ncustom_stopwords = set(stopwords.words('english'))\ncustom_stopwords.update(['href', 'div', 'span', 'class', 'dquo'])\ncustom_stopwords.update(['br', 'ldquo', 'p', 'mdash', 'footnote', 'rsquo',\n                         'rdquo', 'pagenum', 'u','width','nbsp', 'id', 'FNanchor', 'name', 'page', \n                         'pagei', 'hb', 'stanza', 'said', 'one', 'say', 'would', 'right', 'lnumber', 'Quixote', 'Sancho',\n                        'linenum', 'F', 'label', 'label', 'pfn', 'F', 'h', 'td td', 'Luther', 'may', 'see', 'make', 'man', 'come',\n                        'b', 'trtd', 'thy', 'thee', 'like', 'td td', 'tr', 'td', 'pg', 'love', 'know', 'good', 'though', 'shall',\n                        'us', 'poem', 'yet', '.', 'let', 'must', 'well', 'could', 'project gutenberg', 'ln'])\n\n# Read the text files from the directory\ntext = ''\nfor filename in os.listdir('1500-1700_texts'):\n    # Add an if statement to skip hidden directories\n    if not filename.startswith('.'):\n        with open(f'1500-1700_texts/{filename}', 'r', encoding='ISO-8859-1') as f:\n            text += f.read()\n# Remove non-alphabetic characters\ntext = re.sub('[^A-Za-z]+', ' ', text)\n\n# Generate the wordcloud\nwc = WordCloud(width=500, height=600, background_color='black', stopwords=custom_stopwords).generate(text)\n\n# Display the wordcloud\nplt.imshow(wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()\n\n\nimport seaborn as sns\n\n# read in the dataset\ndf = pd.read_csv(\"data set literature.csv\")\n\n# create new columns for the word counts of \"time\" and \"god\" in each book\ndf['Time Count'] = 0\ndf['God Count'] = 0\n\n# loop through each book file and count the number of times the words \"time\" and \"god\" appear\nfor i, row in df.iterrows():\n    filename = f'book{i}.txt'\n    try:\n        with open(filename, 'r', encoding='iso-8859-1') as f:\n            contents = f.read()\n            words = contents.lower().split()\n            time_count = words.count('time')\n            god_count = words.count('god')\n            df.at[i, 'Time Count'] = time_count\n            df.at[i, 'God Count'] = god_count\n    except FileNotFoundError:\n        pass\n\n# filter the dataframe to only include books published between 1500 and 1700\nfiltered_df = df[(df['Date'] >= 1500) & (df['Date'] <= 1700)]\n\n# group the filtered dataframe by year and sum the word counts\ngrouped_df = filtered_df.groupby('Date')[['Time Count', 'God Count']].sum()\n\n# plot a heatmap of the word counts over the years\nsns.heatmap(grouped_df, cmap=\"YlGnBu\")\nplt.title('Usage of the words \"time\" and \"god\" in novels published from 1500 to 1902')\nplt.xlabel('Word')\nplt.ylabel('Year')\nplt.show()\n\n\n\n\n\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\n\n\n\n\n\n\nThis heatmap and wordcloud analyze the occurrence of “God” and “Time” in literature from the 1500-1700 period. The comparison provides insight into the relative importance and prevalence of these concepts during that time. The heatmap shows that “God” was more commonly used than “Time” in these works, which aligns with the religious and theological nature of many texts during this era. See outlier information for the reason why “time” is so prevalent within this corpus.\n\n\nConclusion\nIn conclusion, distant reading provides a valuable tool for literary scholars to study literature within its broader historical context and to identify patterns and trends such as the one presented above. Though not without its faults, and still requiring human interaction, with a human touch, distant reading becomes a welcome companion to close reading. The analysis of this dataset of literary works through distant reading techniques provides a unique insight into the changing cultural and social trends over time. By examining the usage of certain words and themes across different periods, in this instance the word “time”, subtle shifts in human thought and behavior become clear. For example, the case study presented by the aggregated data highlights the growing importance of time and the clock in society, starting from pre-industrialzied eras, right up to the twentieth century. The lack of the word “time” in the earlier works suggests that in the collective thought “time” as it came to be known in the modern definition was a direct result of the workplaces of the Industrial Revolution, caused by its dependance on hourly shifts and train schedules.\n\n\nImportant Note\nWhile I tried to be encompassing with my dataset, I do realize it is small and therefore limited. While there’s a wealth of information on literature published in previous centuries on Wikipedia, I was reliant on what was available on Project Gutenberg, which did not have everything. I hope to continue to develop this project possibly for my Digital Humanities capstone.\n\n\nReferences\nRaymer, Miles. “Review: Miguel De Cervantes’s ‘Don Quixote.’” words and dirt RSS. Accessed March 18, 2023. http://www.words-and-dirt.com/words/review-miguel-de-cervantess-don-quixote/#:~:text=It’s%20hard%20to%20overstate%20how,two%20or%20three%20centuries%20later.\nSchivelbusch, Wolfgang. The Railway Journey the Industrialization of Time and Space in the 19. Century. Leamington Spa: Berg, 1986.\nSeed, David. “The Narrative Method of Dracula.” Nineteenth-Century Fiction 40, no. 1 (1985): 61–75. https://doi.org/10.2307/3044836.\nSherman, Stuart. Telling Time: Clocks, Diaries, and English Diurnal Form, 1660-1785. Chicago: University of Chicago Press, 1997.\nYahav, Amit S. Feeling Time: Duration, the Novel, and Eighteenth-Century Sensibility. Philadelphia: University of Pennsylvania Press, 2018."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinalBlog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReading Time: The Invention of Time Throughout the Industrial Revolution\n\n\n\n\n\nDH_140_Final\n\n\n\n\n\n\nMar 18, 2023\n\n\nZiggy Ghassemi\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]